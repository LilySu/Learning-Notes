{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Word_Phrase_Endpoint_Refactoring3.ipynb","provenance":[{"file_id":"1lzgS2wLsNu788X4aySnTQJf1Pztw-zHc","timestamp":1578013832144}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"AKzD21T4acWg","colab_type":"code","outputId":"7216f99e-bcb8-4070-bb36-3dff3b648f7d","executionInfo":{"status":"ok","timestamp":1578503788128,"user_tz":300,"elapsed":6242,"user":{"displayName":"Lily Su","photoUrl":"https://lh3.googleusercontent.com/-dxYCk9QgeIY/AAAAAAAAAAI/AAAAAAAAAxw/IaW-Bj-2K7k/s64/photo.jpg","userId":"18245831014653329821"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["#breaks reviews up into individual words, tallies up word occurrences and extracts phrases where word appears.\n","#spacy and scattertext are not used because the results are decent without it and for companies with few reviews, compute time is instant.\n","\n","\n","import json\n","import warnings\n","import pandas as pd\n","import numpy as np\n","from lxml import html\n","from requests import Session\n","from concurrent.futures import ThreadPoolExecutor as Executor\n","import requests\n","import re\n","pd.options.display.max_rows = 999\n","pd.options.display.max_columns = 999\n","pd.set_option('display.max_colwidth', 1000)\n","base_url = \"https://www.yelp.com/biz/\" \n","api_url = \"/review_feed?sort_by=date_desc&start=\"\n","bid = 'On6d83tR7_twBBRFzEH6HA'\n","\n","\n","class Scraper():\n","    def __init__(self):\n","        self.data = pd.DataFrame()\n","\n","    def get_data(self, n, bid=bid):\n","        with Session() as s:\n","            with s.get(base_url+bid+api_url+str(n*20)) as resp: #makes an http get request to given url and returns response as json\n","                r = json.loads(resp.content) #converts json response into a dictionary\n","                _html = html.fromstring(r['review_list']) #loads from dictionary\n","\n","                dates = _html.xpath(\"//div[@class='review-content']/descendant::span[@class='rating-qualifier']/text()\")\n","                reviews = [el.text for el in _html.xpath(\"//div[@class='review-content']/p\")]\n","                ratings = _html.xpath(\"//div[@class='review-content']/descendant::div[@class='biz-rating__stars']/div/@title\")\n","\n","                df = pd.DataFrame([dates, reviews, ratings]).T\n","\n","                self.data = pd.concat([self.data,df])\n","\n","    def scrape(self): #makes it faster\n","        # multithreaded looping\n","        with Executor(max_workers=40) as e:\n","            list(e.map(self.get_data, range(10)))\n","\n","s = Scraper()\n","s.scrape()\n","df = s.data\n","df = df.dropna()\n","\n","df['word_segments_unpacked'] = df[1].apply(lambda x: x[1:-1].split(' '))#turn string comma separated list per word\n","\n","df['word_segments_unpacked'] = df['word_segments_unpacked'].astype(str)\n","df['word_segments_unpacked'] = df['word_segments_unpacked'].apply(lambda x: ''.join([str(i) for i in x]))\n","phrase_count = df[['word_segments_unpacked', 2]]\n","\n","\n","s= phrase_count.apply(lambda x: pd.Series(x['word_segments_unpacked']),axis=1).stack().reset_index(level=1, drop=True)\n","s.name = 'word_segments_unpacked'\n","\n","phrase_count = phrase_count.drop('word_segments_unpacked', axis=1).join(s)\n","phrase_count = pd.DataFrame(df['word_segments_unpacked'].str.split(',').tolist(), index=df[2]).stack()\n","\n","phrase_count = phrase_count.reset_index()[[0, 2]] # var1 variable is currently labeled 0\n","phrase_count.columns = ['word_segments_unpacked', 'ratings'] # renaming var1\n","phrase_count = phrase_count.reset_index(drop=False)\n","replace_dict_phrase_count = {'[':'',']':'','-':'','!':'','.':'',' ':'',\"'\":''}\n","for key in replace_dict_phrase_count.keys():\n","  phrase_count['word_segments_unpacked'] = phrase_count['word_segments_unpacked'].str.replace(key, replace_dict_phrase_count[key])\n","phrase_count['word_segments_unpacked'] = phrase_count['word_segments_unpacked'].str.lower()\n","\n","stopwords = [')','(','\\(','\\xa0','0','1','2','3','4','5','6','7','8','9','/','$',\"'d\",\"'ll\",\"'m\",'+','maybe','from','first','here','only','put','where','got','sure','definitely','food','yet','our','go','since','really','very','two',\"n't\",'with','if',\"'s\",'which','came','all','me','(',')','makes','make','were','immediately','get','been','ahead','also','that','one','have','see','what','to','we','had','.',\"'re\",'it','or','he','she','we','us','how','went','no','\"','of','has','by','bit','thing','place','so','ok','and','they','none','was','you',\"'ve\",'did','be','and','but','is','as','&','you','has','-',':','and','had','was','him','so','my','did','would','her','him','it','is','by','bit','thing','place','[',']','while','check-in','=','= =','want', 'good','husband', 'want','love','something','your','they','your','cuz','him',\"i've\",'her','told', 'check', 'i\"m', \"it's\",'they', 'this','its','they','this',\"don't\",'the',',', 'it', 'i\"ve', 'i\"m', '!', '1','2','3','4', '5','6','7','8','9','0','/','.']\n","def filter_stopwords(text):\n","  for i in str(text):\n","    if i not in stopwords:\n","      return str(text)\n","\n","#if item in stopwords list partially matches, delete, single letters like 'i' would be deleted from inside individual words if in list\n","phrase_count = phrase_count[~phrase_count['word_segments_unpacked'].isin(stopwords)]\n","#if the following words fully matches, filter out\n","full_match_list = ['i','a','an','am','at','are','in','on','for','','\\xa0\\xa0','\\xa0','\\(']\n","phrase_count = phrase_count[~phrase_count['word_segments_unpacked'].isin(full_match_list)]\n","\n","#pivot table ratings\n","phrase_count_pivot = pd.pivot_table(phrase_count, index='word_segments_unpacked', columns='ratings', aggfunc='count', fill_value=0)\n","phrase_count_pivot.columns = [''.join(col).strip() for col in phrase_count_pivot.columns.values]#flatten index levels part 1\n","phrase_count_pivot = pd.DataFrame(phrase_count_pivot.to_records())#flatten index levels part 2\n","\n","#if there are no _# star reviews, add a column of zeros\n","required_column_names = ['index1.0 star rating', 'index2.0 star rating','index3.0 star rating','index4.0 star rating','index5.0 star rating']\n","for i in required_column_names:\n","  if i not in phrase_count_pivot.columns:\n","    phrase_count_pivot[i] = 0\n","phrase_count_pivot.sample(10)\n","\n","#replace the original count by getting an exaggerated scaled tally of reviews to calculate score\n","phrase_count_pivot['index1.0 star rating'] = phrase_count_pivot['index1.0 star rating']*(-2)\n","phrase_count_pivot['index2.0 star rating'] = phrase_count_pivot['index2.0 star rating']*(-1)\n","phrase_count_pivot['index3.0 star rating'] = phrase_count_pivot['index3.0 star rating']*(-0.1)\n","phrase_count_pivot['index4.0 star rating'] = phrase_count_pivot['index4.0 star rating']*(1)\n","phrase_count_pivot['index5.0 star rating'] = phrase_count_pivot['index5.0 star rating']*(2)\n","\n","#get a total score from the sum of exaggerated scores\n","phrase_count_pivot['score'] = phrase_count_pivot['index1.0 star rating'] + phrase_count_pivot['index2.0 star rating'] + phrase_count_pivot['index3.0 star rating'] + phrase_count_pivot['index4.0 star rating'] + phrase_count_pivot['index5.0 star rating']\n","\n","phrase_count_pivot['score'] = phrase_count_pivot['score'].div(phrase_count_pivot['score'].max(), axis=0)#normalize\n","phrase_count_pivot['score'] = phrase_count_pivot['score'].round(decimals=4)#round to 4 decimal places\n","phrase_count_pivot = phrase_count_pivot.sort_values(by=('score'), ascending=False)\n","phrase_count_pivot.head(2)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word_segments_unpacked</th>\n","      <th>index5.0 star rating</th>\n","      <th>index1.0 star rating</th>\n","      <th>index2.0 star rating</th>\n","      <th>index3.0 star rating</th>\n","      <th>index4.0 star rating</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>43</th>\n","      <td>tape</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.0</td>\n","      <td>0</td>\n","      <td>1.0000</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>\"painters\"</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.0</td>\n","      <td>0</td>\n","      <td>0.3333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   word_segments_unpacked  index5.0 star rating  index1.0 star rating  \\\n","43                   tape                     6                     0   \n","0              \"painters\"                     2                     0   \n","\n","    index2.0 star rating  index3.0 star rating  index4.0 star rating   score  \n","43                     0                  -0.0                     0  1.0000  \n","0                      0                  -0.0                     0  0.3333  "]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"r-14Zh1YQMpR","colab":{}},"source":["phrase_count_pivot['word_segments_unpacked'] = phrase_count_pivot['word_segments_unpacked'].str.replace('\\(', '')\n","phrase_count_pivot['word_segments_unpacked'] = phrase_count_pivot['word_segments_unpacked'].str.replace('(', '')\n","phrase_count_pivot['word_segments_unpacked'] = phrase_count_pivot['word_segments_unpacked'].str.replace(')', '')#without these, errors incurr\n","\n","worst_terms_list = [] \n","top_terms_list = []\n","x,y = phrase_count_pivot.shape#tuple unpacking to get the length of the dataframe\n","for i in reversed(range(x)):\n","  try:\n","    new_df = df[df[1].str.contains(phrase_count_pivot['word_segments_unpacked'].iloc[i])]#if word appears in review, create a dataframe with each row being the word occurring in a different review\n","    neg_first_df = new_df.sort_values(by=2, ascending=True)#rank the dataframe with worst reviews first\n","    pos_first_df = new_df.sort_values(by=2, ascending=False)#rank the dataframe with most positive reviews first\n","    if neg_first_df[1].iloc[0] not in worst_terms_list:#get the lowest star rating review\n","      worst_terms_list.append(neg_first_df[1].iloc[0])#prevent duplicates\n","    if pos_first_df[1].iloc[0] not in top_terms_list:#get the highest star rating review\n","      top_terms_list.append(pos_first_df[1].iloc[0])\n","  except IndexError as e:\n","    pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMc4NAWQavn5","colab_type":"code","colab":{}},"source":["negative_list = []\n","for i in range(-30,0):#take the worst 30 terms\n","  for list_of_words in worst_terms_list:\n","    word_list = list_of_words.split(' ')\n","    for word in word_list:\n","      word = word.replace(',','')\n","      word = word.replace('.','')\n","      try: \n","        if phrase_count_pivot['word_segments_unpacked'].iloc[i] == word: #find word occurrence in original comma separated word list of reviews\n","          try:\n","            index = word_list.index(word)\n","            string_from_phrases = ','.join(word_list[max(0,index-5):min(index+20, len(word_list))])\n","            replace_dict_string_from_phrases= {'\\xa0':'',' ':'',',':' ',' .':'.','!':'','[':'',']':'','\\n':'','1':'','2':'','3':'','4':'','5':'','6':'','7':'','8':'','9':'','0':'','/':'',\"'\":\"'\",\"'\":''}\n","            for key in replace_dict_string_from_phrases.keys():\n","              string_from_phrases=string_from_phrases.replace(key, replace_dict_string_from_phrases[key])\n","            negative_list.append(string_from_phrases)\n","          except ValueError as e:\n","            pass\n","      except IndexError as e:#if there are less than 30 words after stopword filtering, just get the first word and its occurrence in the original review\n","        if phrase_count_pivot['word_segments_unpacked'].iloc[0] == word:\n","          try:\n","            index = word_list.index(word)\n","            string_from_phrases = ','.join(word_list[max(0,index-5):min(index+20, len(word_list))])\n","            replace_dict_string_from_phrases= {'\\xa0':'',' ':'',',':' ',' .':'.','!':'','[':'',']':'','\\n':'','1':'','2':'','3':'','4':'','5':'','6':'','7':'','8':'','9':'','0':'','/':'',\"'\":\"'\",\"'\":''}\n","            for key in replace_dict_string_from_phrases.keys():\n","              string_from_phrases=string_from_phrases.replace(key, replace_dict_string_from_phrases[key])\n","            negative_list.append(string_from_phrases)\n","          except ValueError as e:\n","            pass\n","negative_df = pd.DataFrame(negative_list)\n","negative_df = negative_df.reset_index(drop=False)\n","negative_df = negative_df.rename(columns={'index':'score', 0 : 'term'})\n","negative_df = negative_df.drop_duplicates(subset='term')\n","x,y = negative_df.shape#tuple unpacking to get the length of the dataframe\n","if x < 10:\n","  for i in range(-40,-30):\n","    for list_of_words in worst_terms_list:\n","      word_list = list_of_words.split(' ')\n","      for word in word_list:\n","        word = word.replace(',','')\n","        word = word.replace('.','')\n","        try:\n","          if phrase_count_pivot['word_segments_unpacked'].iloc[i] == word:\n","            try:\n","              index = word_list.index(word)\n","              string_from_phrases = ','.join(word_list[max(0,index-5):min(index+20, len(word_list))])\n","              replace_dict = {'\\xa0':'',' ':'',',':' ',' .':'.','!':'','[':'',']':'','\\n':'','1':'','2':'','3':'','4':'','5':'','6':'','7':'','8':'','9':'','0':'','/':'',\"'\":\"'\",\"'\":''}\n","              for key in replace_dict.keys():\n","                string_from_phrases=string_from_phrases.replace(key, replace_dict[key])\n","              negative_list.append(string_from_phrases)\n","            except ValueError as e:\n","              pass\n","        except IndexError as e:\n","          if phrase_count_pivot['word_segments_unpacked'].iloc[0] == word:\n","            try:\n","              index = word_list.index(word)\n","              string_from_phrases = ','.join(word_list[max(0,index-5):min(index+20, len(word_list))])\n","              replace_dict_string_from_phrases= {'\\xa0':'',' ':'',',':' ',' .':'.','!':'','[':'',']':'','\\n':'','1':'','2':'','3':'','4':'','5':'','6':'','7':'','8':'','9':'','0':'','/':'',\"'\":\"'\",\"'\":''}\n","              for key in replace_dict_string_from_phrases.keys():\n","                string_from_phrases=string_from_phrases.replace(key, replace_dict_string_from_phrases[key])\n","              negative_list.append(string_from_phrases)\n","            except ValueError as e:\n","              pass\n","negative_df_addon = pd.DataFrame(negative_list)\n","negative_df_addon = negative_df_addon.reset_index(drop=False)\n","negative_df_addon = negative_df_addon.rename(columns={'index':'score', 0 : 'term'})\n","negative_df = pd.concat([negative_df, negative_df_addon])\n","negative_df = negative_df.head(10)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cl1Aqp7ta0j_","colab_type":"code","colab":{}},"source":["positive_list = []\n","for i in range(0,30):\n","  for list_of_words in top_terms_list:\n","    word_list = list_of_words.split(' ')\n","    for word in word_list:\n","      word = word.replace(',','')\n","      word = word.replace('.','')\n","      try: \n","        if phrase_count_pivot['word_segments_unpacked'].iloc[i] == word:\n","          try:\n","            index = word_list.index(word)\n","            string_from_phrases = ','.join(word_list[max(0,index-5):min(index+20, len(word_list))])\n","            replace_dict = {'\\xa0':'',' ':'',',':' ',' .':'.','!':'','[':'',']':'','\\n':'','1':'','2':'','3':'','4':'','5':'','6':'','7':'','8':'','9':'','0':'','/':'',\"'\":\"'\",\"'\":''}\n","            for key in replace_dict.keys():\n","              string_from_phrases=string_from_phrases.replace(key, replace_dict[key])\n","            negative_list.append(string_from_phrases)\n","          except ValueError as e:\n","            pass\n","      except IndexError as e:\n","        if phrase_count_pivot['word_segments_unpacked'].iloc[0] == word:\n","          try:\n","            index = word_list.index(word)\n","            string_from_phrases = ','.join(word_list[max(0,index-5):min(index+20, len(word_list))])\n","            replace_dict = {'\\xa0':'',' ':'',',':' ',' .':'.','!':'','[':'',']':'','\\n':'','1':'','2':'','3':'','4':'','5':'','6':'','7':'','8':'','9':'','0':'','/':'',\"'\":\"'\",\"'\":''}\n","            for key in replace_dict.keys():\n","              string_from_phrases=string_from_phrases.replace(key, replace_dict[key])\n","            negative_list.append(string_from_phrases)\n","          except ValueError as e:\n","            pass\n","  positive_list.append(string_from_phrases)\n","positive_df = pd.DataFrame(positive_list)\n","positive_df = positive_df.reset_index(drop=False)\n","positive_df = positive_df.rename(columns={'index':'score', 0 : 'term'})\n","positive_df = positive_df.drop_duplicates(subset='term')\n","x,y = positive_df.shape#tuple unpacking to get the length of the dataframe\n","for i in range(30,40):\n","  for list_of_words in top_terms_list:\n","    word_list = list_of_words.split(' ')\n","    for word in word_list:\n","      word = word.replace(',','')\n","      word = word.replace('.','')\n","      try:\n","        if phrase_count_pivot['word_segments_unpacked'].iloc[i] == word:\n","          try:\n","            index = word_list.index(word)\n","            string_from_phrases = ','.join(word_list[max(0,index-5):min(index+20, len(word_list))])\n","            replace_dict = {'\\xa0':'',' ':'',',':' ',' .':'.','!':'','[':'',']':'','\\n':'','1':'','2':'','3':'','4':'','5':'','6':'','7':'','8':'','9':'','0':'','/':'',\"'\":\"'\",\"'\":''}\n","            for key in replace_dict.keys():\n","              string_from_phrases=string_from_phrases.replace(key, replace_dict[key])\n","            negative_list.append(string_from_phrases)\n","          except ValueError as e:\n","            pass\n","      except IndexError as e:\n","        if phrase_count_pivot['word_segments_unpacked'].iloc[0] == word:\n","          try:\n","            index = word_list.index(word)\n","            string_from_phrases = ','.join(word_list[max(0,index-5):min(index+20, len(word_list))])\n","            replace_dict = {'\\xa0':'',' ':'',',':' ',' .':'.','!':'','[':'',']':'','\\n':'','1':'','2':'','3':'','4':'','5':'','6':'','7':'','8':'','9':'','0':'','/':'',\"'\":\"'\",\"'\":''}\n","            for key in replace_dict.keys():\n","              string_from_phrases=string_from_phrases.replace(key, replace_dict[key])\n","            negative_list.append(string_from_phrases)\n","          except ValueError as e:\n","            pass\n","positive_df_addon = pd.DataFrame(negative_list)\n","positive_df_addon = positive_df_addon.reset_index(drop=False)\n","positive_df_addon = positive_df_addon.rename(columns={'index':'score', 0 : 'term'})\n","positive_df = pd.concat([positive_df, positive_df_addon])\n","positive_df = positive_df.head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KdxKAvi8M-2J","colab_type":"code","outputId":"67924e66-a1ef-40ad-8703-aad43375ec62","executionInfo":{"status":"ok","timestamp":1578503800739,"user_tz":300,"elapsed":633,"user":{"displayName":"Lily Su","photoUrl":"https://lh3.googleusercontent.com/-dxYCk9QgeIY/AAAAAAAAAAI/AAAAAAAAAxw/IaW-Bj-2K7k/s64/photo.jpg","userId":"18245831014653329821"}},"colab":{"base_uri":"https://localhost:8080/","height":709}},"source":["results = {'positive': [{'term': pos_term, 'score': pos_score} for pos_term, pos_score in zip(positive_df['term'], positive_df['score'])], 'negative': [{'term': neg_term, 'score': neg_score} for neg_term, neg_score in zip(negative_df['term'], negative_df['score'])]}\n","results"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'negative': [{'score': 0,\n","   'term': 'realized I needed some plumbers tape and had no idea where it might be. But I went to the \"tape\" section of our newly organized'},\n","  {'score': 3,\n","   'term': 'cabinet and it was right there (along with the painters tape  packing tape and masking tape)  allowing me to complete my project before I went'},\n","  {'score': 4,\n","   'term': 'to charity and what to throw away. Just this morning I realized I needed some plumbers tape and had no idea where it might be.'},\n","  {'score': 5,\n","   'term': 'chaos. She was able to understand the interpersonal dynamics of our family and help us make decisions about what to save  what to sell  what'},\n","  {'score': 6,\n","   'term': 'had no idea where it might be. But I went to the \"tape\" section of our newly organized supply cabinet and it was right there'},\n","  {'score': 7,\n","   'term': 'was able to understand the interpersonal dynamics of our family and help us make decisions about what to save  what to sell  what to donate'},\n","  {'score': 8,\n","   'term': 'plumbers tape and had no idea where it might be. But I went to the \"tape\" section of our newly organized supply cabinet and it'},\n","  {'score': 9,\n","   'term': 'But I went to the \"tape\" section of our newly organized supply cabinet and it was right there (along with the painters tape  packing tape'},\n","  {'score': 10,\n","   'term': 'out of chaos. She was able to understand the interpersonal dynamics of our family and help us make decisions about what to save  what to'},\n","  {'score': 11,\n","   'term': 'and help us make decisions about what to save  what to sell  what to donate to charity and what to throw away. Just this morning'}],\n"," 'positive': [{'score': 0,\n","   'term': 'realized I needed some plumbers tape and had no idea where it might be. But I went to the \"tape\" section of our newly organized'},\n","  {'score': 2,\n","   'term': 'away. Just this morning I realized I needed some plumbers tape and had no idea where it might be. But I went to the \"tape\"'},\n","  {'score': 4,\n","   'term': 'to throw away. Just this morning I realized I needed some plumbers tape and had no idea where it might be. But I went to'},\n","  {'score': 5,\n","   'term': 'this morning I realized I needed some plumbers tape and had no idea where it might be. But I went to the \"tape\" section of'},\n","  {'score': 6,\n","   'term': 'the \"tape\" section of our newly organized supply cabinet and it was right there (along with the painters tape  packing tape and masking tape)  allowing'},\n","  {'score': 7,\n","   'term': 'Emma helped us create order out of chaos. She was able to understand the interpersonal dynamics of our family and help us make decisions'},\n","  {'score': 8,\n","   'term': '\"tape\" section of our newly organized supply cabinet and it was right there (along with the painters tape  packing tape and masking tape)  allowing me'},\n","  {'score': 9,\n","   'term': 'Emma helped us create order out of chaos. She was able to understand the interpersonal dynamics of our family and help us make decisions about'},\n","  {'score': 10,\n","   'term': '(along with the painters tape  packing tape and masking tape)  allowing me to complete my project before I went to work. '},\n","  {'score': 11,\n","   'term': 'allowing me to complete my project before I went to work. '}]}"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"PN4eR2M5YOa6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}