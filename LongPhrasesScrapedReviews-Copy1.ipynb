{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import math\n",
    "\n",
    "import ssl\n",
    "import urllib.request as request\n",
    "from concurrent.futures import ThreadPoolExecutor as Executor\n",
    "from requests import Session\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "\n",
    "import scattertext as st\n",
    "\n",
    "nlp = st.WhitespaceNLP.whitespace_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "rds_host  = \"\"\n",
    "name = \"\" \n",
    "db_name = \"\" \n",
    "password = \"\"\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(host=rds_host, user=name, password=password, database=db_name, port=5432, connect_timeout=5)\n",
    "except psycopg2.OperationalError as e:\n",
    "    logger.error(\"ERROR: Unexpected error: Could not connect to postGreSQL instance.\")\n",
    "    logger.error(e)\n",
    "    sys.exit()\n",
    "\n",
    "logger.info(\"SUCCESS: Connection to RDS postGreSQL instance succeeded\")\n",
    "\n",
    "\n",
    "def getLatestReviews(business_id, \n",
    "                     limit=200):\n",
    "    sql = f'''\n",
    "    SELECT date, \n",
    "           text,\n",
    "           stars::INTEGER\n",
    "    FROM tallyds.yelp_review\n",
    "    WHERE business_id = '{business_id}'\n",
    "    ORDER BY datetime DESC\n",
    "    LIMIT {limit};\n",
    "    '''\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(sql)\n",
    "        # return a list of tuples\n",
    "        return cursor.fetchall()\n",
    "    \n",
    "data = getLatestReviews(\"jga_2HO_j4I7tSYf5cCEnQ\")\n",
    "df_reviews = pd.DataFrame(data, columns=['date', 'text', 'stars'])\n",
    "df_reviews = df_reviews.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['stars'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPosNegLongPhrases(df_reviews, topk=10):\n",
    "#     df = pd.DataFrame(results)\n",
    "#     df = df.rename(columns={0: 'date', 1: 'stars', 2: 'reviewText', 3: 'review_id', 4: 'user_id'})\n",
    "    df = df_reviews \n",
    "    df['stars'] = df['stars'].astype(str)\n",
    "    df = df.dropna()\n",
    "    df['only_alphabets'] = df['text'].apply(lambda x: ' '.join(re.findall(\"[a-zA-Z]+\", x)))\n",
    "\n",
    "    replace_dict_phrase_count = {'[':'',']':'','-':'','!':'','.':'',\"'\":''}\n",
    "    for key in replace_dict_phrase_count.keys():\n",
    "        df['only_alphabets'] = df['only_alphabets'].str.replace(key, replace_dict_phrase_count[key])\n",
    "        df['only_alphabets'] = df['only_alphabets'].str.lower()\n",
    "\n",
    "    stopwords = ['\"','+','@','&','*','\\\\',')','(','\\(','\\xa0','0','1','2','3','4','5','6','7','8','9','/','$',\"'d\",\"'ll\",\"'m\",'+','maybe','from','first','here','only','put','where','got','sure','definitely','food','yet','our','go','since','really','very','two',\"n't\",'with','if',\"'s\",'which','came','all','me','(',')','makes','make','were','immediately','get','been','ahead','also','that','one','have','see','what','to','we','had','.',\"'re\",'it','or','he','she','we','us','how','went','no','\"','of','has','by','bit','thing','place','so','ok','and','they','none','was','you',\"'ve\",'did','be','and','but','is','as','&','you','has','-',':','and','had','was','him','so','my','did','would','her','him','it','is','by','bit','thing','place','[',']','while','check-in','=','= =','want', 'good','husband', 'want','love','something','your','they','your','cuz','him',\"i've\",'her','told', 'check', 'i\"m', \"it's\",'they', 'this','its','they','this',\"don't\",'the',',', 'it', 'i\"ve', 'i\"m', '!', '1','2','3','4', '5','6','7','8','9','0','/','.']\n",
    "    def filter_stopwords(text):\n",
    "        for i in str(text):\n",
    "            if i not in stopwords:\n",
    "                return str(text)\n",
    "\n",
    "    #if item in stopwords list partially matches, delete, single letters like 'i' would be deleted from inside individual words if in list\n",
    "    df = df[~df['only_alphabets'].isin(stopwords)]\n",
    "    # if the following words fully matches, filter out\n",
    "    full_match_list = ['i','a','an','am','at','are','in','on','for','','\\xa0\\xa0','\\xa0','\\(']\n",
    "    df = df[~df['only_alphabets'].isin(full_match_list)]\n",
    "\n",
    "    corpus = st.CorpusFromPandas(df,\n",
    "                                 category_col='stars',\n",
    "                                 text_col='only_alphabets',\n",
    "                                 nlp=nlp).build()\n",
    "    term_freq_df = corpus.get_term_freq_df()\n",
    "    term_freq_df = pd.DataFrame(term_freq_df.to_records())#flatten multi-level index to rename columns\n",
    "    term_freq_df = term_freq_df.rename(columns = {'5 freq': '5.0', '4 freq': '4.0','2 freq': '2.0', '1 freq': '1.0' })\n",
    "\n",
    "    categories = df['stars'].unique()\n",
    "    high = np.array([])\n",
    "    if '5' in categories:\n",
    "        high = corpus.get_scaled_f_scores('5')\n",
    "    elif '4' in categories:\n",
    "        high = corpus.get_scaled_f_scores('4')\n",
    "    if '1'  in categories:\n",
    "        high =  corpus.get_scaled_f_scores('1')\n",
    "    elif '2' in categories:\n",
    "        high = corpus.get_scaled_f_scores('2')\n",
    "\n",
    "    df_wordFreq = pd.DataFrame()\n",
    "    columns = ['term', 'score']\n",
    "    if high.shape[0] > 0:\n",
    "        df_wordFreq = pd.DataFrame([term_freq_df.term.tolist(), high]).T\n",
    "        df_wordFreq = df_wordFreq.sort_values(1, ascending=True)#.head(topk)\n",
    "        df_wordFreq.columns = columns\n",
    "\n",
    "    x, y = df_wordFreq.shape\n",
    "    top_terms_list = []\n",
    "    for i in range(math.ceil(x/3)):\n",
    "    # for i in range(100):\n",
    "        try:\n",
    "            new_df = df[df['only_alphabets'].str.contains(df_wordFreq['term'].iloc[i])]#if word appears in review, create a dataframe with each row being the word occurring in a different review\n",
    "            pos_first_df = new_df.sort_values(by='stars', ascending=False)#rank the dataframe with most positive reviews first\n",
    "            if pos_first_df['text'].iloc[0] not in top_terms_list:#get the highest star rating review\n",
    "                top_terms_list.append(pos_first_df['text'].iloc[0])\n",
    "#                 top_terms_list.append(pos_first_df['text'].iloc[1])\n",
    "        except IndexError as e:\n",
    "            pass\n",
    "    worst_terms_list = [] \n",
    "    for i in reversed(range(math.ceil(x/3), x)):\n",
    "    # for i in range(-50,0):\n",
    "        try:\n",
    "            new_df = df[df['only_alphabets'].str.contains(df_wordFreq['term'].iloc[i])]#if word appears in review, create a dataframe with each row being the word occurring in a different review\n",
    "            neg_first_df = new_df.sort_values(by='stars', ascending=True)#rank the dataframe with worst reviews first\n",
    "            if neg_first_df['text'].iloc[0] not in worst_terms_list:#get the lowest star rating review\n",
    "                worst_terms_list.append(neg_first_df['text'].iloc[0])#prevent duplicates\n",
    "#                 worst_terms_list.append(neg_first_df['text'].iloc[1])#prevent duplicates\n",
    "        except IndexError as e:\n",
    "            pass\n",
    "    del [df]\n",
    "    negative_list = []\n",
    "    # for i in range(-30,0):#take the worst 30 terms\n",
    "    for i in reversed(range(math.ceil(2*x/3), x)):\n",
    "        for list_of_words in worst_terms_list:\n",
    "            word_list = list_of_words.split(' ')\n",
    "            for word in word_list:\n",
    "                try: \n",
    "                    if df_wordFreq['term'].iloc[i] == word: #find word occurrence in original comma separated word list of reviews\n",
    "                        try:\n",
    "                            index = word_list.index(word)\n",
    "                            string_from_phrases = ' '.join(word_list[max(0,index-2):min(index+4, len(word_list))])\n",
    "                            negative_list.append(string_from_phrases)\n",
    "                        except ValueError as e:\n",
    "                            pass\n",
    "                except IndexError as e:#if there are less than 30 words after stopword filtering, just get the first word and its occurrence in the original review\n",
    "                    if df_wordFreq['term'].iloc[0] == word:\n",
    "                        try:\n",
    "                            index = word_list.index(word)\n",
    "                            string_from_phrases = ' '.join(word_list[max(0,index-2):min(index+4, len(word_list))])\n",
    "                            negative_list.append(string_from_phrases)\n",
    "                        except ValueError as e:\n",
    "                            pass\n",
    "    negative_df = pd.DataFrame(negative_list)\n",
    "    negative_df = negative_df.reset_index(drop=False)\n",
    "\n",
    "    negative_df = negative_df.rename(columns={'index':'score', 0 : 'term'})\n",
    "    negative_df = negative_df.drop_duplicates(subset='term')\n",
    "    x,y = negative_df.shape#tuple unpacking to get the length of the dataframe\n",
    "    if x < 0:\n",
    "        # for i in range(-40,-30):\n",
    "        for i in reversed(range(math.ceil(x/3), math.ceil(2*x/3))):\n",
    "            for list_of_words in worst_terms_list:\n",
    "                word_list = list_of_words.split(' ')\n",
    "                for word in word_list:\n",
    "                    try:\n",
    "                        if df_wordFreq['term'].iloc[i] == word:\n",
    "                            try:\n",
    "                                index = word_list.index(word)\n",
    "                                string_from_phrases = ','.join(word_list[max(0,index-2):min(index+4, len(word_list))])\n",
    "                                negative_list.append(string_from_phrases)\n",
    "                            except ValueError as e:\n",
    "                                pass\n",
    "                    except IndexError as e:\n",
    "                        if df_wordFreq['term'].iloc[0] == word:\n",
    "                            try:\n",
    "                                index = word_list.index(word)\n",
    "                                string_from_phrases = ','.join(word_list[max(0,index-2):min(index+4, len(word_list))])\n",
    "                                negative_list.append(string_from_phrases)\n",
    "                            except ValueError as e:\n",
    "                                pass\n",
    "    negative_df_addon = pd.DataFrame(negative_list)\n",
    "    negative_df_addon = negative_df_addon.reset_index(drop=False)\n",
    "    negative_df_addon = negative_df_addon.rename(columns={'index':'score', 0 : 'term'})\n",
    "    negative_df = pd.concat([negative_df, negative_df_addon])\n",
    "    negative_df['term'] = negative_df['term'].str.replace(',',' ')\n",
    "    negative_df['term'] = negative_df['term'].str.replace('\\u00a0',' ')\n",
    "\n",
    "    positive_list = []\n",
    "    for i in range(math.ceil(x/3)):\n",
    "    # for i in range(0,30):\n",
    "        for list_of_words in top_terms_list:\n",
    "            word_list = list_of_words.split(' ')\n",
    "            for word in word_list:\n",
    "                try: \n",
    "                    if df_wordFreq['term'].iloc[i] == word:\n",
    "                        try:\n",
    "                            index = word_list.index(word)\n",
    "                            string_from_phrases = ','.join(word_list[max(0,index-2):min(index+4, len(word_list))])\n",
    "                            positive_list.append(string_from_phrases)\n",
    "                        except ValueError as e:\n",
    "                            pass\n",
    "                except IndexError as e:\n",
    "                    if df_wordFreq['term'].iloc[0] == word:\n",
    "                        try:\n",
    "                            index = word_list.index(word)\n",
    "                            string_from_phrases = ','.join(word_list[max(0,index-2):min(index+4, len(word_list))])\n",
    "                            positive_list.append(string_from_phrases)\n",
    "                        except ValueError as e:\n",
    "                            pass\n",
    "    positive_df = pd.DataFrame(positive_list)\n",
    "    positive_df = positive_df.reset_index(drop=False)\n",
    "    positive_df = positive_df.rename(columns={'index':'score', 0 : 'term'})\n",
    "    positive_df = positive_df.drop_duplicates(subset='term')\n",
    "    x,y = positive_df.shape#tuple unpacking to get the length of the dataframe\n",
    "    # for i in range(30,40):\n",
    "    for i in range((math.ceil(x/3))+1, math.ceil(x/1.5)):\n",
    "        for list_of_words in top_terms_list:\n",
    "            word_list = list_of_words.split(' ')\n",
    "            for word in word_list:\n",
    "                try:\n",
    "                    if df_wordFreq['term'].iloc[i] == word:\n",
    "                        try:\n",
    "                            index = word_list.index(word)\n",
    "                            string_from_phrases = ','.join(word_list[max(0,index-2):min(index+4, len(word_list))])\n",
    "                            positive_list.append(string_from_phrases)\n",
    "                        except ValueError as e:\n",
    "                            pass\n",
    "                except IndexError as e:\n",
    "                    if df_wordFreq['term'].iloc[0] == word:\n",
    "                        try:\n",
    "                            index = word_list.index(word)\n",
    "                            string_from_phrases = ','.join(word_list[max(0,index-2):min(index+4, len(word_list))])\n",
    "                            positive_list.append(string_from_phrases)\n",
    "                        except ValueError as e:\n",
    "                            pass\n",
    "    del [df_wordFreq]\n",
    "    positive_df_addon = pd.DataFrame(positive_list)\n",
    "    positive_df_addon = positive_df_addon.reset_index(drop=False)\n",
    "    positive_df_addon = positive_df_addon.rename(columns={'index':'score', 0 : 'term'})\n",
    "    positive_df = pd.concat([positive_df, positive_df_addon])\n",
    "    positive_df['term'] = positive_df['term'].str.replace(',',' ')\n",
    "    negative_df['term'] = negative_df['term'].str.replace('\\u00a0',' ')\n",
    "    return positive_df.head(topk), negative_df.tail(topk)\n",
    "\n",
    "\n",
    "def getDataViztype0(business_id):\n",
    "    ''' Deleted on 2020-01-13\n",
    "    # do web scraping \n",
    "    yelpScraperResult = yelpScraper(business_id)\n",
    "    '''\n",
    "    data = getLatestReviews(business_id, limit=200)\n",
    "    if len(data)==0:\n",
    "        return {}\n",
    "    df_reviews = pd.DataFrame(data, columns=['date', 'text', 'stars'])\n",
    "    del data\n",
    "    df_reviews['date'] = pd.to_datetime(df_reviews['date'])\n",
    "\n",
    "    # viztype0\n",
    "    df_positive, df_negative = getPosNegLongPhrases(df_reviews)\n",
    "    positive, negative = [], []\n",
    "    if not df_positive.empty:\n",
    "        positive = [{'term': row[0], 'score': row[1]} \n",
    "            for row in df_positive[['term', 'score']].values]\n",
    "    if not df_negative.empty:\n",
    "        negative = [{'term': row[0], 'score': row[1]} \n",
    "            for row in df_negative[['term', 'score']].values]\n",
    "    viztype0 = {\n",
    "        'positive': positive, \n",
    "        'negative': negative\n",
    "    }\n",
    "    del [df_positive, df_negative]\n",
    "    \n",
    "    results = {\n",
    "    'viztype0': viztype0\n",
    "\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'viztype0': {'positive': [{'term': 'recommend that you stop by!', 'score': 0},\n",
       "   {'term': 'make sure you mesh this is', 'score': 1},\n",
       "   {'term': 'is what you would expect from', 'score': 2},\n",
       "   {'term': 'to adopt you can get to', 'score': 3},\n",
       "   {'term': 'guests. \\xa0If you like cats this', 'score': 5},\n",
       "   {'term': 'sure that you respect the cats', 'score': 6},\n",
       "   {'term': 'are everywhere you look. Bob Marley', 'score': 11},\n",
       "   {'term': 'Some let you hold them and', 'score': 12},\n",
       "   {'term': 'of toys you can play with', 'score': 13},\n",
       "   {'term': \"even if you don't have those\", 'score': 18}],\n",
       "  'negative': [{'term': 'and am counting down the days', 'score': 1922},\n",
       "   {'term': 'the days til I can come', 'score': 1923},\n",
       "   {'term': 'atmosphere and ambiance made it so', 'score': 1924},\n",
       "   {'term': 'and sweet  explained the \"terms and', 'score': 1925},\n",
       "   {'term': 'a pretty decent sized space too.', 'score': 1926},\n",
       "   {'term': 'pretty decent sized space too. The', 'score': 1927},\n",
       "   {'term': 'with a tiny staff and small', 'score': 1928},\n",
       "   {'term': 'and small budget that are still', 'score': 1929},\n",
       "   {'term': 'but you may encounter a couple+', 'score': 1930},\n",
       "   {'term': 'you may encounter a couple+ messes.', 'score': 1931}]}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_id = \"jga_2HO_j4I7tSYf5cCEnQ\"\n",
    "\n",
    "getDataViztype0(business_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive, df_negative = getPosNegLongPhrases(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4937</td>\n",
       "      <td>4937</td>\n",
       "      <td>The employee informed me they're still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4938</td>\n",
       "      <td>4938</td>\n",
       "      <td>with an unhealthy amount of cats.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4939</td>\n",
       "      <td>4939</td>\n",
       "      <td>my camera roll with an unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4940</td>\n",
       "      <td>4940</td>\n",
       "      <td>fill my camera roll with an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4941</td>\n",
       "      <td>4941</td>\n",
       "      <td>me the opportunity to fill my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4942</td>\n",
       "      <td>4942</td>\n",
       "      <td>them. Also allowed gave me the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4943</td>\n",
       "      <td>4943</td>\n",
       "      <td>to shelter  letting people get to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4944</td>\n",
       "      <td>4944</td>\n",
       "      <td>a nice alternative to shelter  letting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4945</td>\n",
       "      <td>4945</td>\n",
       "      <td>play with/snuggle/give treats is a bargain!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4946</td>\n",
       "      <td>4946</td>\n",
       "      <td>but am hoping to soon! The</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                                           term\n",
       "4937   4937         The employee informed me they're still\n",
       "4938   4938              with an unhealthy amount of cats.\n",
       "4939   4939               my camera roll with an unhealthy\n",
       "4940   4940                    fill my camera roll with an\n",
       "4941   4941                  me the opportunity to fill my\n",
       "4942   4942                 them. Also allowed gave me the\n",
       "4943   4943              to shelter  letting people get to\n",
       "4944   4944         a nice alternative to shelter  letting\n",
       "4945   4945  play with/snuggle/give treats is a bargain!!!\n",
       "4946   4946                     but am hoping to soon! The"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'term': 'need to update their hours on', 'score': 0},\n",
       " {'term': 'website. My daughter has been talking', 'score': 9},\n",
       " {'term': 'has been talking about coming here', 'score': 18},\n",
       " {'term': 'open at noon and not the', 'score': 27},\n",
       " {'term': 'they have posted on their website.\\n\\nSorry', 'score': 36},\n",
       " {'term': 'for the smudged face prints on', 'score': 45},\n",
       " {'term': 'smudged face prints on your windows....', 'score': 54},\n",
       " {'term': 'There was no cafe. No coffee', 'score': 63},\n",
       " {'term': 'will allow no more than 15', 'score': 67},\n",
       " {'term': 'ambience  look no further! LaGattara is', 'score': 68}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = [{'term': row[0], 'score': row[1]} \n",
    "            for row in df_positive[['term', 'score']].values]\n",
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'viztype0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5254e68f74e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mviztype0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'viztype0' is not defined"
     ]
    }
   ],
   "source": [
    "viztype0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
